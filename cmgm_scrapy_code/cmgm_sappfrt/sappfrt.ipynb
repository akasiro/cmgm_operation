{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "scrapytoolv2_path = os.path.join('..', 'scrapy_toolv2')\n",
    "sys.path.append(scrapytoolv2_path)\n",
    "from html_downloader import html_downloader as hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sappfrt():\n",
    "    def __init__(self, path, first_index_url):\n",
    "        self.first_index_url = first_index_url\n",
    "        self.hd = hd(world=True)\n",
    "        self.path = os.path.join('data',path)\n",
    "        if not os.path.exists(self.path):\n",
    "            os.makedirs(self.path)\n",
    "    def parse_index_page(self, index_url, page_url=[]):\n",
    "        r = self.hd.request_proxy(index_url)\n",
    "        soup = BeautifulSoup(r.content,'html.parser')\n",
    "        content_div = soup.find('div', {'class':'jar2l_list'})\n",
    "        lis = content_div.find_all('li')\n",
    "        for l in lis:\n",
    "            tmp_url = l.a.get('href')\n",
    "            tmp_url = urljoin(index_url, tmp_url)\n",
    "            tmp_title = l.a.get_text()\n",
    "            page_url.append([tmp_url, tmp_title])\n",
    "        \n",
    "        pages = soup.find('div', {'class':'page'})\n",
    "        if pages:\n",
    "            page_boxes = pages.find_all('a', {'class':'m2page_a'})\n",
    "            for p in page_boxes:\n",
    "                if p.get_text() == '>':\n",
    "                    next_page = p\n",
    "            next_page_url = next_page.get('href')\n",
    "            if '.shtml' in next_page_url:\n",
    "                next_page_url = urljoin(index_url, next_page_url)\n",
    "                if next_page_url != index_url:\n",
    "                    self.parse_index_page(next_page_url, page_url=page_url)\n",
    "        return page_url\n",
    "    def parse_content_page(self, page_url):\n",
    "        r = self.hd.request_proxy(page_url[0])\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        table_div = soup.find('div', {'id':'artibody'})\n",
    "        target_table = table_div.find('table')\n",
    "        trs = target_table.find_all('tr')\n",
    "        data = {}\n",
    "        for i in range(0,len(trs)):\n",
    "            if i:\n",
    "                columns = list(data.keys())\n",
    "                tds = trs[i].find_all('td')\n",
    "                for j in range(0,len(tds)):\n",
    "                    data[columns[j]].append(re.sub('\\s','',tds[j].get_text())) \n",
    "            else:\n",
    "                ths = trs[i].find_all('td')\n",
    "                for j in ths:\n",
    "                    data[re.sub('\\s','',j.get_text())] = []\n",
    "        df = pd.DataFrame(data)\n",
    "        df['source_url'] = page_url[0]\n",
    "        df['source'] = page_url[1]\n",
    "        df.to_csv(os.path.join(self.path, '{}.csv'.format(page_url[1])), index=False)\n",
    "        return df\n",
    "    def main(self):\n",
    "        df = pd.DataFrame()\n",
    "        page_url = self.parse_index_page(self.first_index_url)\n",
    "        for p in page_url:\n",
    "            tmpdf = self.parse_content_page(p)\n",
    "            df = df.append(tmpdf)\n",
    "        df.to_csv(os.path.join(self.path, 'total.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "change = 'http://www.sapprft.gov.cn/sapprft/channels/11083.shtml'\n",
    "homemade = 'http://www.sapprft.gov.cn/sapprft/channels/7029.shtml'\n",
    "import_net = 'http://www.sapprft.gov.cn/sapprft/channels/7027.shtml'\n",
    "import_digital = 'http://www.sapprft.gov.cn/sapprft/channels/7028.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "test1 = sappfrt('change', change)\n",
    "test1.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "test2 = sappfrt('homemade',homemade)\n",
    "test2.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "test3 = sappfrt('import_net', import_net)\n",
    "test3.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test4 = sappfrt('import_digital', import_digital)\n",
    "test4.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
